{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from tensorflow.keras.layers import GRU, LSTM, Conv1D, Dense, BatchNormalization, Dropout, Bidirectional, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = [os.path.join('sentiment_analysis', i) for i in os.listdir('sentiment_analysis') if 'train' in i][0]\n",
    "test_file = [os.path.join('sentiment_analysis', i) for i in os.listdir('sentiment_analysis') if 'test' in i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(train_file)\n",
    "test_raw = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>Live out loud #lol #liveoutloud #selfie #smile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>We would like to wish you an amazing day! Make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>Helping my lovely 90 year old neighbor with he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally got my #smart #pocket #wifi stay conne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1        2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2        3      0  We love this! Would you go? #talk #makememorie...\n",
       "3        4      0  I'm wired I know I'm George I was made that wa...\n",
       "4        5      1  What amazing service! Apple won't even talk to...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  Live out loud #lol #liveoutloud #selfie #smile...\n",
       "7916  7917      0  We would like to wish you an amazing day! Make...\n",
       "7917  7918      0  Helping my lovely 90 year old neighbor with he...\n",
       "7918  7919      0  Finally got my #smart #pocket #wifi stay conne...\n",
       "7919  7920      0  Apple Barcelona!!! #Apple #Store #BCN #Barcelo...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_non_word(file):\n",
    "    \n",
    "    for i in range(len(file)):\n",
    "        \n",
    "        file.iloc[i, 2] = re.sub('[^A-Za-z\\s]', '', file.iloc[i, 2])\n",
    "    \n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint Pregnancy Test httpsgooglhMfQV and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case  Thanks to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this Would you go talk makememories un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Im wired I know Im George I was made that way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service Apple wont even talk to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>Live out loud lol liveoutloud selfie smile son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>We would like to wish you an amazing day Make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>Helping my lovely  year old neighbor with her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally got my smart pocket wifi stay connecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple Barcelona Apple Store BCN Barcelona trav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  fingerprint Pregnancy Test httpsgooglhMfQV and...\n",
       "1        2      0  Finally a transparant silicon case  Thanks to ...\n",
       "2        3      0  We love this Would you go talk makememories un...\n",
       "3        4      0  Im wired I know Im George I was made that way ...\n",
       "4        5      1  What amazing service Apple wont even talk to m...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  Live out loud lol liveoutloud selfie smile son...\n",
       "7916  7917      0  We would like to wish you an amazing day Make ...\n",
       "7917  7918      0  Helping my lovely  year old neighbor with her ...\n",
       "7918  7919      0  Finally got my smart pocket wifi stay connecte...\n",
       "7919  7920      0  Apple Barcelona Apple Store BCN Barcelona trav...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_no_nonword = train_raw.copy()\n",
    "train_no_nonword = clean_non_word(train_no_nonword)\n",
    "train_no_nonword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(file):\n",
    "    \n",
    "    for i in range(len(file)):\n",
    "        \n",
    "        file.iloc[i, 2] = file.iloc[i, 2].lower()\n",
    "    \n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnancy test httpsgooglhmfqv and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case  thanks to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this would you go talk makememories un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wired i know im george i was made that way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>what amazing service apple wont even talk to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>live out loud lol liveoutloud selfie smile son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>we would like to wish you an amazing day make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>helping my lovely  year old neighbor with her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>finally got my smart pocket wifi stay connecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>apple barcelona apple store bcn barcelona trav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  fingerprint pregnancy test httpsgooglhmfqv and...\n",
       "1        2      0  finally a transparant silicon case  thanks to ...\n",
       "2        3      0  we love this would you go talk makememories un...\n",
       "3        4      0  im wired i know im george i was made that way ...\n",
       "4        5      1  what amazing service apple wont even talk to m...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  live out loud lol liveoutloud selfie smile son...\n",
       "7916  7917      0  we would like to wish you an amazing day make ...\n",
       "7917  7918      0  helping my lovely  year old neighbor with her ...\n",
       "7918  7919      0  finally got my smart pocket wifi stay connecte...\n",
       "7919  7920      0  apple barcelona apple store bcn barcelona trav...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_no_nonword = lower_case(train_no_nonword)\n",
    "train_no_nonword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_dict = {}\n",
    "def create_word_freq_dict(file):\n",
    "    \n",
    "    global word_freq_dict\n",
    "        \n",
    "    for i in range(len(file)):\n",
    "            \n",
    "        for word in file.iloc[i, 2].split():\n",
    "                \n",
    "            if word not in word_freq_dict.keys():\n",
    "                \n",
    "                word_freq_dict[word] = 1\n",
    "                \n",
    "            else:\n",
    "                    \n",
    "                word_freq_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_word_freq_dict(train_no_nonword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ordered_freq_dict = {k: v for k, v in sorted(word_freq_dict.items(), key = lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6169"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_freq_dict = {k:v for k, v in word_freq_dict.items() if v > 1}\n",
    "len(final_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fingerprint': 1,\n",
       " 'pregnancy': 2,\n",
       " 'test': 3,\n",
       " 'android': 4,\n",
       " 'apps': 5,\n",
       " 'beautiful': 6,\n",
       " 'cute': 7,\n",
       " 'health': 8,\n",
       " 'igers': 9,\n",
       " 'iphoneonly': 10,\n",
       " 'iphonesia': 11,\n",
       " 'iphone': 12,\n",
       " 'finally': 13,\n",
       " 'transparant': 14,\n",
       " 'silicon': 15,\n",
       " 'case': 16,\n",
       " 'thanks': 17,\n",
       " 'uncle': 18,\n",
       " 'yay': 19,\n",
       " 'sony': 20,\n",
       " 'xperia': 21,\n",
       " 'sonyexperias': 22,\n",
       " 'love': 23,\n",
       " 'would': 24,\n",
       " 'go': 25,\n",
       " 'talk': 26,\n",
       " 'makememories': 27,\n",
       " 'unplug': 28,\n",
       " 'relax': 29,\n",
       " 'smartphone': 30,\n",
       " 'wifi': 31,\n",
       " 'connect': 32,\n",
       " 'im': 33,\n",
       " 'wired': 34,\n",
       " 'know': 35,\n",
       " 'george': 36,\n",
       " 'made': 37,\n",
       " 'way': 38,\n",
       " 'daventry': 39,\n",
       " 'home': 40,\n",
       " 'amazing': 41,\n",
       " 'service': 42,\n",
       " 'apple': 43,\n",
       " 'wont': 44,\n",
       " 'even': 45,\n",
       " 'question': 46,\n",
       " 'unless': 47,\n",
       " 'pay': 48,\n",
       " 'stupid': 49,\n",
       " 'support': 50,\n",
       " 'software': 51,\n",
       " 'update': 52,\n",
       " 'fucked': 53,\n",
       " 'phone': 54,\n",
       " 'big': 55,\n",
       " 'time': 56,\n",
       " 'iphones': 57,\n",
       " 'happy': 58,\n",
       " 'us': 59,\n",
       " 'instapic': 60,\n",
       " 'instadaily': 61,\n",
       " 'xperiaz': 62,\n",
       " 'new': 63,\n",
       " 'type': 64,\n",
       " 'c': 65,\n",
       " 'charger': 66,\n",
       " 'cable': 67,\n",
       " 'uk': 68,\n",
       " 'bay': 69,\n",
       " 'amazon': 70,\n",
       " 'etsy': 71,\n",
       " 'year': 72,\n",
       " 'rob': 73,\n",
       " 'cross': 74,\n",
       " 'toby': 75,\n",
       " 'young': 76,\n",
       " 'evemun': 77,\n",
       " 'mcmafia': 78,\n",
       " 'taylor': 79,\n",
       " 'spectre': 80,\n",
       " 'newyear': 81,\n",
       " 'starting': 82,\n",
       " 'recipes': 83,\n",
       " 'technology': 84,\n",
       " 'samsunggalaxys': 85,\n",
       " 'iphonex': 86,\n",
       " 'pictwittercompjiwqwtc': 87,\n",
       " 'bout': 88,\n",
       " 'shopping': 89,\n",
       " 'listening': 90,\n",
       " 'music': 91,\n",
       " 'justme': 92,\n",
       " 'likeforlike': 93,\n",
       " 'followforfollow': 94,\n",
       " 'photo': 95,\n",
       " 'fun': 96,\n",
       " 'selfie': 97,\n",
       " 'pool': 98,\n",
       " 'water': 99,\n",
       " 'camera': 100,\n",
       " 'picoftheday': 101,\n",
       " 'sun': 102,\n",
       " 'instagood': 103,\n",
       " 'boy': 104,\n",
       " 'outdoor': 105,\n",
       " 'hey': 106,\n",
       " 'make': 107,\n",
       " 'ipod': 108,\n",
       " 'dont': 109,\n",
       " 'color': 110,\n",
       " 'inches': 111,\n",
       " 'thinner': 112,\n",
       " 'crash': 113,\n",
       " 'every': 114,\n",
       " 'five': 115,\n",
       " 'fuckin': 116,\n",
       " 'minite': 117,\n",
       " 'ha': 118,\n",
       " 'heavy': 119,\n",
       " 'machinery': 120,\n",
       " 'need': 121,\n",
       " 'really': 122,\n",
       " 'dropped': 123,\n",
       " 'ball': 124,\n",
       " 'design': 125,\n",
       " 'drinkyourhaterade': 126,\n",
       " 'contemplating': 127,\n",
       " 'giving': 128,\n",
       " 'bandwagon': 129,\n",
       " 'simply': 130,\n",
       " 'cellcom': 131,\n",
       " 'androids': 132,\n",
       " 'depressing': 133,\n",
       " 'idontwantto': 134,\n",
       " 'another': 135,\n",
       " 'crazy': 136,\n",
       " 'purchase': 137,\n",
       " 'lol': 138,\n",
       " 'theory': 139,\n",
       " 'work': 140,\n",
       " 'hard': 141,\n",
       " 'play': 142,\n",
       " 'ipad': 143,\n",
       " 'shaqlockholmes': 144,\n",
       " 'samlouise': 145,\n",
       " 'battery': 146,\n",
       " 'painful': 147,\n",
       " 'charge': 148,\n",
       " 'overnight': 149,\n",
       " 'lunchtime': 150,\n",
       " 'dead': 151,\n",
       " 'hateorange': 152,\n",
       " 'deepellum': 153,\n",
       " 'towards': 154,\n",
       " 'downtown': 155,\n",
       " 'dallas': 156,\n",
       " 'bigd': 157,\n",
       " 'saturday': 158,\n",
       " 'rxm': 159,\n",
       " 'summer': 160,\n",
       " 'urban': 161,\n",
       " 'like': 162,\n",
       " 'share': 163,\n",
       " 'want': 164,\n",
       " 'pictwittercomgfknyecj': 165,\n",
       " 'instagram': 166,\n",
       " 'photooftheday': 167,\n",
       " 'tweegram': 168,\n",
       " 'reason': 169,\n",
       " 'one': 170,\n",
       " 'suck': 171,\n",
       " 'truth': 172,\n",
       " 'truthbetold': 173,\n",
       " 'agree': 174,\n",
       " 'fact': 175,\n",
       " 'realitycheck': 176,\n",
       " 'blackberrypictwittercomzpggdcazn': 177,\n",
       " 'store': 178,\n",
       " 'gunna': 179,\n",
       " 'screens': 180,\n",
       " 'monday': 181,\n",
       " 'ur': 182,\n",
       " 'fucking': 183,\n",
       " 'fuckingpissed': 184,\n",
       " 'art': 185,\n",
       " 'easter': 186,\n",
       " 'dear': 187,\n",
       " 'friends': 188,\n",
       " 'published': 189,\n",
       " 'channel': 190,\n",
       " 'face': 191,\n",
       " 'bunny': 192,\n",
       " 'email': 193,\n",
       " 'png': 194,\n",
       " 'thumbnail': 195,\n",
       " 'mutitaedibleartgmailcompictwittercomjhwphfbgt': 196,\n",
       " 'excuse': 197,\n",
       " 'waiter': 198,\n",
       " 'seems': 199,\n",
       " 'pie': 200,\n",
       " 'soup': 201,\n",
       " 'wife': 202,\n",
       " 'bake': 203,\n",
       " 'ive': 204,\n",
       " 'four': 205,\n",
       " 'days': 206,\n",
       " 'button': 207,\n",
       " 'back': 208,\n",
       " 'broke': 209,\n",
       " 'accidentally': 210,\n",
       " 'hit': 211,\n",
       " 'screen': 212,\n",
       " 'goes': 213,\n",
       " 'completely': 214,\n",
       " 'black': 215,\n",
       " 'keep': 216,\n",
       " 'getting': 217,\n",
       " 'texts': 218,\n",
       " 'day': 219,\n",
       " 'cant': 220,\n",
       " 'check': 221,\n",
       " 'thiphone': 222,\n",
       " 'wallpapers': 223,\n",
       " 'wall': 224,\n",
       " 'galaxy': 225,\n",
       " 'samsung': 226,\n",
       " 'app': 227,\n",
       " 'billion': 228,\n",
       " 'patents': 229,\n",
       " 'prior': 230,\n",
       " 'millions': 231,\n",
       " 'patent': 232,\n",
       " 'trolls': 233,\n",
       " 'partying': 234,\n",
       " 'messed': 235,\n",
       " 'havent': 236,\n",
       " 'done': 237,\n",
       " 'nothing': 238,\n",
       " 'myloss': 239,\n",
       " 'touch': 240,\n",
       " 'frozen': 241,\n",
       " 'logo': 242,\n",
       " 'starts': 243,\n",
       " 'lose': 244,\n",
       " 'demis': 245,\n",
       " 'pics': 246,\n",
       " 'kill': 247,\n",
       " 'someone': 248,\n",
       " 'soangry': 249,\n",
       " 'hateapple': 250,\n",
       " 'flower': 251,\n",
       " 'green': 252,\n",
       " 'diamond': 253,\n",
       " 'pearls': 254,\n",
       " 'must': 255,\n",
       " 'watch': 256,\n",
       " 'youtube': 257,\n",
       " 'subscribe': 258,\n",
       " 'daily': 259,\n",
       " 'vlog': 260,\n",
       " 'twitch': 261,\n",
       " 'gaming': 262,\n",
       " 'ps': 263,\n",
       " 'xbox': 264,\n",
       " 'games': 265,\n",
       " 'ios': 266,\n",
       " 'thank': 267,\n",
       " 'live': 268,\n",
       " 'laugh': 269,\n",
       " 'life': 270,\n",
       " 'food': 271,\n",
       " 'philippines': 272,\n",
       " 'instago': 273,\n",
       " 'instahub': 274,\n",
       " 'ch': 275,\n",
       " 'cannon': 276,\n",
       " 'suewee': 277,\n",
       " 'friendship': 278,\n",
       " 'americanbully': 279,\n",
       " 'dog': 280,\n",
       " 'piggies': 281,\n",
       " 'family': 282,\n",
       " 'southerncharm': 283,\n",
       " 'americanidol': 284,\n",
       " 'goals': 285,\n",
       " 'bestfriends': 286,\n",
       " 'pitbull': 287,\n",
       " 'onelove': 288,\n",
       " 'country': 289,\n",
       " 'muscle': 290,\n",
       " 'nfl': 291,\n",
       " 'worldwide': 292,\n",
       " 'america': 293,\n",
       " 'bigboy': 294,\n",
       " 'thislife': 295,\n",
       " 'tmz': 296,\n",
       " 'wild': 297,\n",
       " 'hoggpictwittercommnogpic': 298,\n",
       " 'mimmoal': 299,\n",
       " 'feb': 300,\n",
       " 'taken': 301,\n",
       " 'rx': 302,\n",
       " 'direzioneverticale': 303,\n",
       " 'sunset': 304,\n",
       " 'sky': 305,\n",
       " 'pictwittercomcxifijjg': 306,\n",
       " 'sister': 307,\n",
       " 'bought': 308,\n",
       " 'early': 309,\n",
       " 'bday': 310,\n",
       " 'gift': 311,\n",
       " 'received': 312,\n",
       " 'note': 313,\n",
       " 'many': 314,\n",
       " 'cottds': 315,\n",
       " 'nswrl': 316,\n",
       " 'market': 317,\n",
       " 'pipeline': 318,\n",
       " 'delete': 319,\n",
       " 'individual': 320,\n",
       " 'songs': 321,\n",
       " 'itunes': 322,\n",
       " 'everybody': 323,\n",
       " 'freaking': 324,\n",
       " 'duuude': 325,\n",
       " 'windows': 326,\n",
       " 'phones': 327,\n",
       " 'advanced': 328,\n",
       " 'customization': 329,\n",
       " 'standing': 330,\n",
       " 'sirriiously': 331,\n",
       " 'bad': 332,\n",
       " 'cheap': 333,\n",
       " 'res': 334,\n",
       " 'tech': 335,\n",
       " 'bull': 336,\n",
       " 'instasize': 337,\n",
       " 'leggings': 338,\n",
       " 'lightskin': 339,\n",
       " 'curlyhair': 340,\n",
       " 'bellypiercing': 341,\n",
       " 'smile': 342,\n",
       " 'potd': 343,\n",
       " 'dint': 344,\n",
       " 'create': 345,\n",
       " 'let': 346,\n",
       " 'destroy': 347,\n",
       " 'candid': 348,\n",
       " 'sunday': 349,\n",
       " 'sundayvibes': 350,\n",
       " 'always': 351,\n",
       " 'eyes': 352,\n",
       " 'ootd': 353,\n",
       " 'fashion': 354,\n",
       " 'blackandwhite': 355,\n",
       " 'poser': 356,\n",
       " 'attitude': 357,\n",
       " 'lifeisgood': 358,\n",
       " 'mylook': 359,\n",
       " 'mylife': 360,\n",
       " 'photoeveryday': 361,\n",
       " 'lookoftheday': 362,\n",
       " 'latepost': 363,\n",
       " 'mylifepictwittercommmhcqyadb': 364,\n",
       " 'film': 365,\n",
       " 'set': 366,\n",
       " 'building': 367,\n",
       " 'timelapse': 368,\n",
       " 'video': 369,\n",
       " 'producer': 370,\n",
       " 'videoproduction': 371,\n",
       " 'follow': 372,\n",
       " 'commercial': 373,\n",
       " 'actor': 374,\n",
       " 'actress': 375,\n",
       " 'hollywood': 376,\n",
       " 'losangeles': 377,\n",
       " 'movies': 378,\n",
       " 'acting': 379,\n",
       " 'startup': 380,\n",
       " 'startupvideos': 381,\n",
       " 'shotoniphonpictwittercomeceiaine': 382,\n",
       " 'cupcakes': 383,\n",
       " 'wallpaper': 384,\n",
       " 'pink': 385,\n",
       " 'sweet': 386,\n",
       " 'cherries': 387,\n",
       " 'eeeeee': 388,\n",
       " 'sexy': 389,\n",
       " 'ladies': 390,\n",
       " 'iphon': 391,\n",
       " 'acquisto': 392,\n",
       " 'del': 393,\n",
       " 'week': 394,\n",
       " 'end': 395,\n",
       " 'iphoneplus': 396,\n",
       " 'gril': 397,\n",
       " 'moment': 398,\n",
       " 'italy': 399,\n",
       " 'majestic': 400,\n",
       " 'see': 401,\n",
       " 'differently': 402,\n",
       " 'photography': 403,\n",
       " 'nature': 404,\n",
       " 'landscape': 405,\n",
       " 'forest': 406,\n",
       " 'hidden': 407,\n",
       " 'clearing': 408,\n",
       " 'view': 409,\n",
       " 'woods': 410,\n",
       " 'tree': 411,\n",
       " 'travel': 412,\n",
       " 'biker': 413,\n",
       " 'ziess': 414,\n",
       " 'instgramhub': 415,\n",
       " 'google': 416,\n",
       " 'cut': 417,\n",
       " 'get': 418,\n",
       " 'program': 419,\n",
       " 'ahhhh': 420,\n",
       " 'look': 421,\n",
       " 'got': 422,\n",
       " 'christmas': 423,\n",
       " 'girl': 424,\n",
       " 'instacool': 425,\n",
       " 'bitcoinboy': 426,\n",
       " 'free': 427,\n",
       " 'game': 428,\n",
       " 'kansas': 429,\n",
       " 'georgia': 430,\n",
       " 'ogochocinco': 431,\n",
       " 'talking': 432,\n",
       " 'antoine': 433,\n",
       " 'ent': 434,\n",
       " 'appstore': 435,\n",
       " 'joy': 436,\n",
       " 'peace': 437,\n",
       " 'reflect': 438,\n",
       " 'remember': 439,\n",
       " 'cloud': 440,\n",
       " 'cloudhub': 441,\n",
       " 'skyhub': 442,\n",
       " 'gr': 443,\n",
       " 'baby': 444,\n",
       " 'babyboy': 445,\n",
       " 'muesli': 446,\n",
       " 'hedgehog': 447,\n",
       " 'pet': 448,\n",
       " 'inbox': 449,\n",
       " 'letters': 450,\n",
       " 'editor': 451,\n",
       " 'news': 452,\n",
       " 'fail': 453,\n",
       " 'funny': 454,\n",
       " 'lolpictwittercomikrhumovz': 455,\n",
       " 'zsofimonster': 456,\n",
       " 'faster': 457,\n",
       " 'hated': 458,\n",
       " 'ye': 459,\n",
       " 'jamesdawute': 460,\n",
       " 'tablets': 461,\n",
       " 'personally': 462,\n",
       " 'use': 463,\n",
       " 'sense': 464,\n",
       " 'fan': 465,\n",
       " 'think': 466,\n",
       " 'quite': 467,\n",
       " 'gd': 468,\n",
       " 'product': 469,\n",
       " 'friday': 470,\n",
       " 'called': 471,\n",
       " 'blackfridaydeals': 472,\n",
       " 'blackfriday': 473,\n",
       " 'shop': 474,\n",
       " 'holidays': 475,\n",
       " 'gifts': 476,\n",
       " 'newyork': 477,\n",
       " 'business': 478,\n",
       " 'crowds': 479,\n",
       " 'money': 480,\n",
       " 'birthday': 481,\n",
       " 'tv': 482,\n",
       " 'computer': 483,\n",
       " 'lifehacks': 484,\n",
       " 'school': 485,\n",
       " 'seriously': 486,\n",
       " 'afraid': 487,\n",
       " 'profit': 488,\n",
       " 'going': 489,\n",
       " 'elses': 490,\n",
       " 'pocket': 491,\n",
       " 'chargers': 492,\n",
       " 'arent': 493,\n",
       " 'supported': 494,\n",
       " 'pos': 495,\n",
       " 'month': 496,\n",
       " 'good': 497,\n",
       " 'job': 498,\n",
       " 'actually': 499,\n",
       " 'killing': 500,\n",
       " 'paying': 501,\n",
       " 'replacement': 502,\n",
       " 'thats': 503,\n",
       " 'still': 504,\n",
       " 'programmed': 505,\n",
       " 'basic': 506,\n",
       " 'rt': 507,\n",
       " 'sloanlovescudi': 508,\n",
       " 'sucks': 509,\n",
       " 'droid': 510,\n",
       " 'waitwhat': 511,\n",
       " 'double': 512,\n",
       " 'saw': 513,\n",
       " 'alyssa': 514,\n",
       " 'h': 515,\n",
       " 'cool': 516,\n",
       " 'picture': 517,\n",
       " 'l': 518,\n",
       " 'cycle': 519,\n",
       " 'complete': 520,\n",
       " 'froot': 521,\n",
       " 'run': 522,\n",
       " 'beach': 523,\n",
       " 'sport': 524,\n",
       " 'tysonj': 525,\n",
       " 'bit': 526,\n",
       " 'hypocritical': 527,\n",
       " 'hashtag': 528,\n",
       " 'yet': 529,\n",
       " 'quivering': 530,\n",
       " 'anticipation': 531,\n",
       " 'arrival': 532,\n",
       " 'gain': 533,\n",
       " 'followers': 534,\n",
       " 'everyone': 535,\n",
       " 'rts': 536,\n",
       " 'sougofollow': 537,\n",
       " 'ff': 538,\n",
       " 'isi': 539,\n",
       " 'geometry': 540,\n",
       " 'iphoneography': 541,\n",
       " 'streetphotography': 542,\n",
       " 'iphonephotography': 543,\n",
       " 'mobilephotography': 544,\n",
       " 'mobile': 545,\n",
       " 'colors': 546,\n",
       " 'bright': 547,\n",
       " 'users': 548,\n",
       " 'fettish': 549,\n",
       " 'techno': 550,\n",
       " 'indie': 551,\n",
       " 'dating': 552,\n",
       " 'okcupid': 553,\n",
       " 'less': 554,\n",
       " 'random': 555,\n",
       " 'instamood': 556,\n",
       " 'loljk': 557,\n",
       " 'shine': 558,\n",
       " 'wine': 559,\n",
       " 'amaliexmaria': 560,\n",
       " 'copenhagen': 561,\n",
       " 'creative': 562,\n",
       " 'composer': 563,\n",
       " 'denmark': 564,\n",
       " 'hot': 565,\n",
       " 'iconic': 566,\n",
       " 'keepthefaith': 567,\n",
       " 'mariajensen': 568,\n",
       " 'original': 569,\n",
       " 'pop': 570,\n",
       " 'red': 571,\n",
       " 'rock': 572,\n",
       " 'soul': 573,\n",
       " 'singer': 574,\n",
       " 'songwriter': 575,\n",
       " 'song': 576,\n",
       " 'universal': 577,\n",
       " 'warnerpictwittercomgbeusyedm': 578,\n",
       " 'tescophoneshop': 579,\n",
       " 'wedding': 580,\n",
       " 'dvd': 581,\n",
       " 'thought': 582,\n",
       " 'id': 583,\n",
       " 'lost': 584,\n",
       " 'meliiecandy': 585,\n",
       " 'ipadmini': 586,\n",
       " 'soldes': 587,\n",
       " 'instamoment': 588,\n",
       " 'planeteig': 589,\n",
       " 'feeling': 590,\n",
       " 'broken': 591,\n",
       " 'replaced': 592,\n",
       " 'happiness': 593,\n",
       " 'pictwittercomygsukeces': 594,\n",
       " 'light': 595,\n",
       " 'please': 596,\n",
       " 'lamp': 597,\n",
       " 'pekanbaru': 598,\n",
       " 'riau': 599,\n",
       " 'indonesia': 600,\n",
       " 'sonya': 601,\n",
       " 'acquisition': 602,\n",
       " 'gold': 603,\n",
       " 'brussels': 604,\n",
       " 'texted': 605,\n",
       " 'reset': 606,\n",
       " 'sorry': 607,\n",
       " 'inception': 608,\n",
       " 'white': 609,\n",
       " 'tea': 610,\n",
       " 'chilling': 611,\n",
       " 'carcasa': 612,\n",
       " 'clear': 613,\n",
       " 'cover': 614,\n",
       " 'para': 615,\n",
       " 'grandprime': 616,\n",
       " 'felizdomingo': 617,\n",
       " 'samsunggalaxy': 618,\n",
       " 'g': 619,\n",
       " 'felizlunes': 620,\n",
       " 'felizsemana': 621,\n",
       " 'oct': 622,\n",
       " 'felizmartespictwittercomxtldsjwpz': 623,\n",
       " 'apples': 624,\n",
       " 'mighty': 625,\n",
       " 'mouse': 626,\n",
       " 'came': 627,\n",
       " 'lithium': 628,\n",
       " 'aas': 629,\n",
       " 'magic': 630,\n",
       " 'comes': 631,\n",
       " 'alkaline': 632,\n",
       " 'nyclesbians': 633,\n",
       " 'followsunday': 634,\n",
       " 'followback': 635,\n",
       " 'teamfollowback': 636,\n",
       " 'retweet': 637,\n",
       " 'ya': 638,\n",
       " 'thing': 639,\n",
       " 'samsunguk': 640,\n",
       " 'tumble': 641,\n",
       " 'dryer': 642,\n",
       " 'months': 643,\n",
       " 'already': 644,\n",
       " 'problem': 645,\n",
       " 'occurred': 646,\n",
       " 'iwant': 647,\n",
       " 'issue': 648,\n",
       " 'resolved': 649,\n",
       " 'able': 650,\n",
       " 'return': 651,\n",
       " 'alexandraeton': 652,\n",
       " 'bbcwatchdog': 653,\n",
       " 'lilya': 654,\n",
       " 'asll': 655,\n",
       " 'sonyas': 656,\n",
       " 'throwback': 657,\n",
       " 'shoot': 658,\n",
       " 'blury': 659,\n",
       " 'pic': 660,\n",
       " 'photos': 661,\n",
       " 'pictwittercombtewbkx': 662,\n",
       " 'cnet': 663,\n",
       " 'call': 664,\n",
       " 'put': 665,\n",
       " 'absurd': 666,\n",
       " 'price': 667,\n",
       " 'device': 668,\n",
       " 'commonwealth': 669,\n",
       " 'skye': 670,\n",
       " 'nicolson': 671,\n",
       " 'wins': 672,\n",
       " 'boxing': 673,\n",
       " 'memory': 674,\n",
       " 'brothers': 675,\n",
       " 'adaptive': 676,\n",
       " 'galatasaray': 677,\n",
       " 'iherborder': 678,\n",
       " 'presidenttrump': 679,\n",
       " 'oh': 680,\n",
       " 'comment': 681,\n",
       " 'lip': 682,\n",
       " 'win': 683,\n",
       " 'getalife': 684,\n",
       " 'tecshit': 685,\n",
       " 'enjoying': 686,\n",
       " 'tombraider': 687,\n",
       " 'laracroft': 688,\n",
       " 'playstation': 689,\n",
       " 'gamer': 690,\n",
       " 'hunger': 691,\n",
       " 'simpsons': 692,\n",
       " 'thehungergames': 693,\n",
       " 'something': 694,\n",
       " 'wrong': 695,\n",
       " 'right': 696,\n",
       " 'today': 697,\n",
       " 'makes': 698,\n",
       " 'item': 699,\n",
       " 'jammieexoxo': 700,\n",
       " 'recommends': 701,\n",
       " 'earphone': 702,\n",
       " 'earpods': 703,\n",
       " 'lifestyle': 704,\n",
       " 'fuckyou': 705,\n",
       " 'never': 706,\n",
       " 'ending': 707,\n",
       " 'bugs': 708,\n",
       " 'payed': 709,\n",
       " 'bucks': 710,\n",
       " 'phonehow': 711,\n",
       " 'little': 712,\n",
       " 'quality': 713,\n",
       " 'hereanotherangrycustomer': 714,\n",
       " 'girlfriend': 715,\n",
       " 'gf': 716,\n",
       " 'bf': 717,\n",
       " 'card': 718,\n",
       " 'z': 719,\n",
       " 'soppy': 720,\n",
       " 'present': 721,\n",
       " 'mom': 722,\n",
       " 'macbookpro': 723,\n",
       " 'macbook': 724,\n",
       " 'stockholm': 725,\n",
       " 'sweden': 726,\n",
       " 'compute': 727,\n",
       " 'quote': 728,\n",
       " 'quotes': 729,\n",
       " 'wisdom': 730,\n",
       " 'words': 731,\n",
       " 'tweetgram': 732,\n",
       " 'applaud': 733,\n",
       " 'sheffield': 734,\n",
       " 'customer': 735,\n",
       " 'great': 736,\n",
       " 'repair': 737,\n",
       " 'hour': 738,\n",
       " 'everything': 739,\n",
       " 'due': 740,\n",
       " 'recovery': 741,\n",
       " 'mode': 742,\n",
       " 'mashable': 743,\n",
       " 'hater': 744,\n",
       " 'yousuck': 745,\n",
       " 'briantong': 746,\n",
       " 'easytotalk': 747,\n",
       " 'producesomething': 748,\n",
       " 'usa': 749,\n",
       " 'company': 750,\n",
       " 'korean': 751,\n",
       " 'loser': 752,\n",
       " 'working': 753,\n",
       " 'servers': 754,\n",
       " 'dumb': 755,\n",
       " 'scheduled': 756,\n",
       " 'maintenance': 757,\n",
       " 'models': 758,\n",
       " 'byhilalak': 759,\n",
       " 'earphones': 760,\n",
       " 'urbanears': 761,\n",
       " 'handmade': 762,\n",
       " 'hayatinarenkkat': 763,\n",
       " 'vicio': 764,\n",
       " 'nellyfurtado': 765,\n",
       " 'nelstar': 766,\n",
       " 'playingnow': 767,\n",
       " 'diva': 768,\n",
       " 'cds': 769,\n",
       " 'features': 770,\n",
       " 'didnt': 771,\n",
       " 'yourtechcompany': 772,\n",
       " 'pictwittercomhsizay': 773,\n",
       " 'box': 774,\n",
       " 'yey': 775,\n",
       " 'sonyxperiaz': 776,\n",
       " 'blessed': 777,\n",
       " 'feliz': 778,\n",
       " 'sbado': 779,\n",
       " 'con': 780,\n",
       " 'caf': 781,\n",
       " 'coffee': 782,\n",
       " 'pantry': 783,\n",
       " 'dreamy': 784,\n",
       " 'effect': 785,\n",
       " 'created': 786,\n",
       " 'straight': 787,\n",
       " 'impressive': 788,\n",
       " 'spring': 789,\n",
       " 'blossom': 790,\n",
       " 'finalllllly': 791,\n",
       " 'galaxynote': 792,\n",
       " 'awsome': 793,\n",
       " 'beamman': 794,\n",
       " 'best': 795,\n",
       " 'special': 796,\n",
       " 'valentine': 797,\n",
       " 'nowplaying': 798,\n",
       " 'daughter': 799,\n",
       " 'poem': 800,\n",
       " 'erie': 801,\n",
       " 'pa': 802,\n",
       " 'car': 803,\n",
       " 'sign': 804,\n",
       " 'iloveyou': 805,\n",
       " 'lunch': 806,\n",
       " 'park': 807,\n",
       " 'carrot': 808,\n",
       " 'banana': 809,\n",
       " 'lovely': 810,\n",
       " 'dogs': 811,\n",
       " 'trees': 812,\n",
       " 'autumn': 813,\n",
       " 'leaves': 814,\n",
       " 'iphonethe': 815,\n",
       " 'confession': 816,\n",
       " 'spend': 817,\n",
       " 'confessing': 818,\n",
       " 'faith': 819,\n",
       " 'sins': 820,\n",
       " 'much': 821,\n",
       " 'book': 822,\n",
       " 'flickr': 823,\n",
       " 'say': 824,\n",
       " 'fuck': 825,\n",
       " 'u': 826,\n",
       " 'updateit': 827,\n",
       " 'took': 828,\n",
       " 'hours': 829,\n",
       " 'download': 830,\n",
       " 'hate': 831,\n",
       " 'westcoast': 832,\n",
       " 'huntington': 833,\n",
       " 'added': 834,\n",
       " 'twitter': 835,\n",
       " 'directory': 836,\n",
       " 'newyorkny': 837,\n",
       " 'education': 838,\n",
       " 'losin': 839,\n",
       " 'reception': 840,\n",
       " 'n': 841,\n",
       " 'missed': 842,\n",
       " 'calls': 843,\n",
       " 'last': 844,\n",
       " 'mins': 845,\n",
       " 'tmobile': 846,\n",
       " 'come': 847,\n",
       " 'jump': 848,\n",
       " 'rid': 849,\n",
       " 'absolutely': 850,\n",
       " 'taste': 851,\n",
       " 'frank': 852,\n",
       " 'oceans': 853,\n",
       " 'annoying': 854,\n",
       " 'finish': 855,\n",
       " 'levels': 856,\n",
       " 'wheres': 857,\n",
       " 'buy': 858,\n",
       " 'full': 859,\n",
       " 'version': 860,\n",
       " 'wear': 861,\n",
       " 'important': 862,\n",
       " 'mood': 863,\n",
       " 'boss': 864,\n",
       " 'blog': 865,\n",
       " 'style': 866,\n",
       " 'wcw': 867,\n",
       " 'wce': 868,\n",
       " 'bestoftheday': 869,\n",
       " 'pretty': 870,\n",
       " 'babe': 871,\n",
       " 'wednesday': 872,\n",
       " 'funpictwittercomggnuvxbv': 873,\n",
       " 'natepgilbraith': 874,\n",
       " 'send': 875,\n",
       " 'turn': 876,\n",
       " 'imessage': 877,\n",
       " 'fanta': 878,\n",
       " 'delish': 879,\n",
       " 'sundayfunday': 880,\n",
       " 'healing': 881,\n",
       " 'sleep': 882,\n",
       " 'lap': 883,\n",
       " 'babygirl': 884,\n",
       " 'popular': 885,\n",
       " 'shes': 886,\n",
       " 'loverly': 887,\n",
       " 'tweet': 888,\n",
       " 'rabbitsofinstagram': 889,\n",
       " 'bunniesofinstagram': 890,\n",
       " 'rabbit': 891,\n",
       " 'hop': 892,\n",
       " 'bounce': 893,\n",
       " 'charlie': 894,\n",
       " 'houserabbit': 895,\n",
       " 'bunnylove': 896,\n",
       " 'rabbitsofig': 897,\n",
       " 'shotoniphone': 898,\n",
       " 'photographer': 899,\n",
       " 'chuck': 900,\n",
       " 'charles': 901,\n",
       " 'pictwittercomgpwnfuzwh': 902,\n",
       " 'valentines': 903,\n",
       " 'lucien': 904,\n",
       " 'swarovski': 905,\n",
       " 'crystal': 906,\n",
       " 'vegan': 907,\n",
       " 'glutenfree': 908,\n",
       " 'silly': 909,\n",
       " 'sallys': 910,\n",
       " 'diner': 911,\n",
       " 'syncing': 912,\n",
       " 'hear': 913,\n",
       " 'seconds': 914,\n",
       " 'mmlp': 915,\n",
       " 'fml': 916,\n",
       " 'candy': 917,\n",
       " 'beatiful': 918,\n",
       " 'beaty': 919,\n",
       " 'nice': 920,\n",
       " 'fo': 921,\n",
       " 'wait': 922,\n",
       " 'hand': 923,\n",
       " 'spacegray': 924,\n",
       " 'gb': 925,\n",
       " 'pictwittercomogogkeopw': 926,\n",
       " 'unpacking': 927,\n",
       " 'compact': 928,\n",
       " 'first': 929,\n",
       " 'impression': 930,\n",
       " 'pictwittercomblobosu': 931,\n",
       " 'muoneoz': 932,\n",
       " 'progress': 933,\n",
       " 'bar': 934,\n",
       " 'key': 935,\n",
       " 'long': 936,\n",
       " 'give': 937,\n",
       " 'cold': 938,\n",
       " 'boot': 939,\n",
       " 'fear': 940,\n",
       " 'itll': 941,\n",
       " 'siri': 942,\n",
       " 'doesnt': 943,\n",
       " 'understand': 944,\n",
       " 'commands': 945,\n",
       " 'nephew': 946,\n",
       " 'allshots': 947,\n",
       " 'endless': 948,\n",
       " 'photoofthaday': 949,\n",
       " 'literally': 950,\n",
       " 'cry': 951,\n",
       " 'contacts': 952,\n",
       " 'andyvaughan': 953,\n",
       " 'looks': 954,\n",
       " 'wonder': 955,\n",
       " 'available': 956,\n",
       " 'b': 957,\n",
       " 'compares': 958,\n",
       " 'al': 959,\n",
       " 'fiiiiin': 960,\n",
       " 'laptop': 961,\n",
       " 'vaio': 962,\n",
       " 'minnie': 963,\n",
       " 'inlove': 964,\n",
       " 'blackberry': 965,\n",
       " 'occasionally': 966,\n",
       " 'fruit': 967,\n",
       " 'falls': 968,\n",
       " 'worry': 969,\n",
       " 'thou': 970,\n",
       " 'soon': 971,\n",
       " 'usernamesplinkio': 972,\n",
       " 'thai': 973,\n",
       " 'curry': 974,\n",
       " 'yum': 975,\n",
       " 'picoft': 976,\n",
       " 'yosemite': 977,\n",
       " 'steep': 978,\n",
       " 'hill': 979,\n",
       " 'climb': 980,\n",
       " 'mac': 981,\n",
       " 'kernel': 982,\n",
       " 'serve': 983,\n",
       " 'wellapple': 984,\n",
       " 'updates': 985,\n",
       " 'warning': 986,\n",
       " 'display': 987,\n",
       " 'upon': 988,\n",
       " 'brbrrylove': 989,\n",
       " 'shesh': 990,\n",
       " 'told': 991,\n",
       " 'stop': 992,\n",
       " 'mojo': 993,\n",
       " 'p': 994,\n",
       " 'three': 995,\n",
       " 'things': 996,\n",
       " 'ship': 997,\n",
       " 'advertisement': 998,\n",
       " 'gear': 999,\n",
       " 'vr': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword = stopwords.words('english')\n",
    "word_list = [k for k in word_freq_dict.keys() if k not in stopword and 'http' not in k]\n",
    "word_index = {v:k+1 for k, v in enumerate(word_list)}\n",
    "word_index['oov'] = len(word_index) + 1\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17317"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_corpus(data):\n",
    "    \n",
    "    max_len = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        temp_len = len(data.iloc[i, 2].split())\n",
    "        \n",
    "        if temp_len > max_len:\n",
    "            \n",
    "            max_len = temp_len\n",
    "    \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pad = longest_corpus(train_no_nonword)\n",
    "max_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_set(file, padding = 'none', max_pad = 50):\n",
    "    \n",
    "    train = []\n",
    "    \n",
    "    global word_index\n",
    "    \n",
    "    for i in range(len(file)):\n",
    "        \n",
    "        sample_train = []\n",
    "        \n",
    "        for word in file.iloc[i, 2].split():\n",
    "            \n",
    "            if word not in stopword:\n",
    "            \n",
    "                try:\n",
    "                    sample_train.append(word_index[word])\n",
    "\n",
    "                except KeyError:\n",
    "                    sample_train.append(len(word_index) + 1)\n",
    "        \n",
    "        if padding != 'none':\n",
    "                    \n",
    "            if len(sample_train) < 52:\n",
    "\n",
    "                if padding == 'post':\n",
    "\n",
    "                    for i in range(int(max_pad) - len(sample_train)):\n",
    "\n",
    "                        sample_train.append(0)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    for i in range(int(max_pad) - len(sample_train)):\n",
    "\n",
    "                        sample_train.insert(0, 0)\n",
    "                \n",
    "\n",
    "        train.append([sample_train, file.iloc[i, 1]])\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full = create_training_set(train_no_nonword, padding = 'post', max_pad = max_pad)\n",
    "train_full[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = math.ceil(len(train_no_nonword) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = np.array(train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set:  6336\n"
     ]
    }
   ],
   "source": [
    "sample_index = np.random.randint(0, len(train_no_nonword), size = len(train_no_nonword))\n",
    "train_df = train_full[sample_index[0:split_point]]\n",
    "val_df = train_full[sample_index[split_point:]]\n",
    "print('Length of training set: ', len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_corpus_label(data):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        x.append(data[i][0])\n",
    "        y.append(data[i][1])\n",
    "    \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24,  162, 1308,   41,  219,  107,  114, 1309, 1310, 1311,  697,\n",
       "         12, 1312,  452,  270, 5691,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = split_corpus_label(train_df)\n",
    "val_x, val_y = split_corpus_label(val_df)\n",
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(word_index)\n",
    "output_dim = 100\n",
    "input_length = max_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = input_dim, output_dim = output_dim, mask_zero = True, \n",
    "                    input_length = input_length, embeddings_initializer=initializers.glorot_uniform(seed=0)))\n",
    "\n",
    "model.add(Conv1D(64, 8, input_shape = [None, 100], activation = 'relu', kernel_initializer=initializers.glorot_uniform(seed=0)))\n",
    "\n",
    "model.add(Bidirectional(GRU(128, return_sequences = True, kernel_initializer=initializers.glorot_uniform(seed=0))))\n",
    "model.add(Bidirectional(GRU(128, return_sequences = False, kernel_initializer=initializers.glorot_uniform(seed=0))))\n",
    "\n",
    "model.add(Dense(256, kernel_initializer=initializers.glorot_uniform(seed=0), kernel_regularizer=tf.keras.regularizers.L1(0.01), activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, kernel_initializer=initializers.glorot_uniform(seed=0), kernel_regularizer=tf.keras.regularizers.L1(0.01), activity_regularizer=tf.keras.regularizers.L2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(lr = 5e-4), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "198/198 [==============================] - 6s 31ms/step - loss: 1.1162 - acc: 0.9871 - val_loss: 1.5215 - val_acc: 0.9028\n",
      "Epoch 2/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.9615 - acc: 0.9874 - val_loss: 1.4216 - val_acc: 0.9047\n",
      "Epoch 3/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.8327 - acc: 0.9871 - val_loss: 1.3002 - val_acc: 0.9066\n",
      "Epoch 4/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.7227 - acc: 0.9877 - val_loss: 1.2433 - val_acc: 0.9059\n",
      "Epoch 5/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.6377 - acc: 0.9880 - val_loss: 1.2103 - val_acc: 0.9053\n",
      "Epoch 6/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.5729 - acc: 0.9882 - val_loss: 1.1959 - val_acc: 0.9028\n",
      "Epoch 7/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.5244 - acc: 0.9886 - val_loss: 1.1832 - val_acc: 0.9053\n",
      "Epoch 8/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.4800 - acc: 0.9893 - val_loss: 1.1606 - val_acc: 0.9047\n",
      "Epoch 9/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.4478 - acc: 0.9899 - val_loss: 1.1821 - val_acc: 0.9015\n",
      "Epoch 10/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.4204 - acc: 0.9907 - val_loss: 1.1927 - val_acc: 0.9047\n",
      "Epoch 11/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3988 - acc: 0.9905 - val_loss: 1.2142 - val_acc: 0.8990\n",
      "Epoch 12/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3819 - acc: 0.9902 - val_loss: 1.2266 - val_acc: 0.8958\n",
      "Epoch 13/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3642 - acc: 0.9908 - val_loss: 1.2396 - val_acc: 0.8984\n",
      "Epoch 14/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3520 - acc: 0.9908 - val_loss: 1.2303 - val_acc: 0.9028\n",
      "Epoch 15/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3441 - acc: 0.9908 - val_loss: 1.2361 - val_acc: 0.9009\n",
      "Epoch 16/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3352 - acc: 0.9913 - val_loss: 1.2217 - val_acc: 0.8939\n",
      "Epoch 17/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3287 - acc: 0.9912 - val_loss: 1.3343 - val_acc: 0.8958\n",
      "Epoch 18/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3220 - acc: 0.9915 - val_loss: 1.2905 - val_acc: 0.8946\n",
      "Epoch 19/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3169 - acc: 0.9915 - val_loss: 1.2821 - val_acc: 0.8939\n",
      "Epoch 20/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3134 - acc: 0.9912 - val_loss: 1.3905 - val_acc: 0.8965\n",
      "Epoch 21/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3090 - acc: 0.9913 - val_loss: 1.3607 - val_acc: 0.9009\n",
      "Epoch 22/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3052 - acc: 0.9910 - val_loss: 1.3524 - val_acc: 0.9009\n",
      "Epoch 23/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3016 - acc: 0.9915 - val_loss: 1.3500 - val_acc: 0.9003\n",
      "Epoch 24/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2994 - acc: 0.9910 - val_loss: 1.3548 - val_acc: 0.8990\n",
      "Epoch 25/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2963 - acc: 0.9915 - val_loss: 1.3815 - val_acc: 0.9015\n",
      "Epoch 26/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2942 - acc: 0.9912 - val_loss: 1.5430 - val_acc: 0.8933\n",
      "Epoch 27/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2903 - acc: 0.9913 - val_loss: 1.4053 - val_acc: 0.9040\n",
      "Epoch 28/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2896 - acc: 0.9905 - val_loss: 1.3555 - val_acc: 0.9034\n",
      "Epoch 29/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2883 - acc: 0.9912 - val_loss: 1.3778 - val_acc: 0.9021\n",
      "Epoch 30/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2842 - acc: 0.9913 - val_loss: 1.3984 - val_acc: 0.8996\n",
      "Epoch 31/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2816 - acc: 0.9913 - val_loss: 1.4241 - val_acc: 0.9021\n",
      "Epoch 32/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2823 - acc: 0.9913 - val_loss: 1.4425 - val_acc: 0.9028\n",
      "Epoch 33/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2781 - acc: 0.9913 - val_loss: 1.4173 - val_acc: 0.9028\n",
      "Epoch 34/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2750 - acc: 0.9913 - val_loss: 1.4650 - val_acc: 0.8996\n",
      "Epoch 35/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2750 - acc: 0.9913 - val_loss: 1.5219 - val_acc: 0.8977\n",
      "Epoch 36/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2745 - acc: 0.9912 - val_loss: 1.4990 - val_acc: 0.9015\n",
      "Epoch 37/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2733 - acc: 0.9912 - val_loss: 1.6270 - val_acc: 0.8984\n",
      "Epoch 38/75\n",
      "198/198 [==============================] - 6s 28ms/step - loss: 0.2710 - acc: 0.9915 - val_loss: 1.5576 - val_acc: 0.9028\n",
      "Epoch 39/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2700 - acc: 0.9913 - val_loss: 1.5571 - val_acc: 0.9028\n",
      "Epoch 40/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2671 - acc: 0.9913 - val_loss: 1.5674 - val_acc: 0.9015\n",
      "Epoch 41/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2754 - acc: 0.9915 - val_loss: 1.5623 - val_acc: 0.9021\n",
      "Epoch 42/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2669 - acc: 0.9915 - val_loss: 1.5370 - val_acc: 0.9015\n",
      "Epoch 43/75\n",
      "198/198 [==============================] - 6s 32ms/step - loss: 0.2633 - acc: 0.9915 - val_loss: 1.5215 - val_acc: 0.9015\n",
      "Epoch 44/75\n",
      "198/198 [==============================] - 6s 30ms/step - loss: 0.2692 - acc: 0.9910 - val_loss: 1.7188 - val_acc: 0.8927 loss: 0.2707 -\n",
      "Epoch 45/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2675 - acc: 0.9910 - val_loss: 1.6596 - val_acc: 0.8977\n",
      "Epoch 46/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2694 - acc: 0.9908 - val_loss: 1.6012 - val_acc: 0.9021\n",
      "Epoch 47/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2700 - acc: 0.9912 - val_loss: 1.6076 - val_acc: 0.9021\n",
      "Epoch 48/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2617 - acc: 0.9913 - val_loss: 1.6191 - val_acc: 0.9009\n",
      "Epoch 49/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2625 - acc: 0.9913 - val_loss: 1.6438 - val_acc: 0.9003\n",
      "Epoch 50/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2643 - acc: 0.9913 - val_loss: 1.6446 - val_acc: 0.9003\n",
      "Epoch 51/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2641 - acc: 0.9913 - val_loss: 1.6398 - val_acc: 0.9009\n",
      "Epoch 52/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2634 - acc: 0.9913 - val_loss: 1.6477 - val_acc: 0.8990\n",
      "Epoch 53/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2587 - acc: 0.9912 - val_loss: 1.6459 - val_acc: 0.8996\n",
      "Epoch 54/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2618 - acc: 0.9910 - val_loss: 1.6448 - val_acc: 0.8996\n",
      "Epoch 55/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2597 - acc: 0.9912 - val_loss: 1.6479 - val_acc: 0.9003\n",
      "Epoch 56/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2643 - acc: 0.9912 - val_loss: 1.6575 - val_acc: 0.8996\n",
      "Epoch 57/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2614 - acc: 0.9907 - val_loss: 1.9205 - val_acc: 0.8819\n",
      "Epoch 58/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2779 - acc: 0.9890 - val_loss: 1.7148 - val_acc: 0.8952\n",
      "Epoch 59/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.5198 - acc: 0.8614 - val_loss: 0.7134 - val_acc: 0.7620\n",
      "Epoch 60/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.7051 - acc: 0.7655 - val_loss: 0.6955 - val_acc: 0.7658\n",
      "Epoch 61/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.6929 - acc: 0.7669 - val_loss: 0.6894 - val_acc: 0.7652\n",
      "Epoch 62/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.6763 - acc: 0.7669 - val_loss: 0.6723 - val_acc: 0.7652\n",
      "Epoch 63/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.6333 - acc: 0.7669 - val_loss: 0.6262 - val_acc: 0.7652\n",
      "Epoch 64/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.5509 - acc: 0.7672 - val_loss: 0.5646 - val_acc: 0.7652\n",
      "Epoch 65/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.4640 - acc: 0.7899 - val_loss: 0.5275 - val_acc: 0.7652\n",
      "Epoch 66/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.4242 - acc: 0.8777 - val_loss: 0.5866 - val_acc: 0.8643\n",
      "Epoch 67/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3832 - acc: 0.9514 - val_loss: 0.4754 - val_acc: 0.8952\n",
      "Epoch 68/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3621 - acc: 0.9747 - val_loss: 0.7036 - val_acc: 0.8990\n",
      "Epoch 69/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3526 - acc: 0.9782 - val_loss: 0.4788 - val_acc: 0.9021\n",
      "Epoch 70/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3541 - acc: 0.9804 - val_loss: 0.6198 - val_acc: 0.9059\n",
      "Epoch 71/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3455 - acc: 0.9855 - val_loss: 0.4950 - val_acc: 0.9040\n",
      "Epoch 72/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3050 - acc: 0.9863 - val_loss: 0.6810 - val_acc: 0.9059\n",
      "Epoch 73/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3146 - acc: 0.9867 - val_loss: 0.8571 - val_acc: 0.9040\n",
      "Epoch 74/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3147 - acc: 0.9863 - val_loss: 0.7231 - val_acc: 0.9028\n",
      "Epoch 75/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3050 - acc: 0.9875 - val_loss: 0.9099 - val_acc: 0.9066\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, batch_size = 32, validation_data = (val_x, val_y), epochs = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = tf.keras.layers.Input(shape = (52,))\n",
    "embed = Embedding(input_dim = input_dim, output_dim = output_dim, mask_zero = True, \n",
    "                  input_length = input_length, embeddings_initializer=initializers.glorot_uniform(seed=0))(input1)\n",
    "\n",
    "conv1 = Conv1D(64, 8, input_shape = [None, 100], activation = 'relu', kernel_initializer=initializers.glorot_uniform(seed=0))(embed)\n",
    "\n",
    "output1, hidden_forward, hidden_backward = Bidirectional(\n",
    "    GRU(128, return_sequences = True, return_state = True, kernel_initializer=initializers.glorot_uniform(seed=0)))(conv1)\n",
    "\n",
    "gru2 = Bidirectional(\n",
    "    GRU(128, return_sequences = False, kernel_initializer=initializers.glorot_uniform(seed=0)))(output1, \n",
    "                                                                                                initial_state = \n",
    "                                                                                                [hidden_forward, hidden_backward])\n",
    "\n",
    "dense1 = Dense(256, kernel_initializer= initializers.glorot_uniform(seed=0), \n",
    "               kernel_regularizer=tf.keras.regularizers.L1(0.01), activity_regularizer=tf.keras.regularizers.L2(0.01))(gru2)\n",
    "dense1 = Dropout(0.5)(dense1)\n",
    "output = Dense(1, kernel_initializer= initializers.glorot_uniform(seed=0), \n",
    "               kernel_regularizer=tf.keras.regularizers.L1(0.01), activity_regularizer=tf.keras.regularizers.L2(0.01))(dense1)\n",
    "\n",
    "state_model = tf.keras.models.Model(inputs = input1, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_model.compile(optimizer = tf.keras.optimizers.Adam(lr = 5e-4), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "198/198 [==============================] - 7s 34ms/step - loss: 14.5582 - acc: 0.7884 - val_loss: 1.0994 - val_acc: 0.8813\n",
      "Epoch 2/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.5588 - acc: 0.9416 - val_loss: 0.5624 - val_acc: 0.9261\n",
      "Epoch 3/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3796 - acc: 0.9785 - val_loss: 0.6997 - val_acc: 0.9356\n",
      "Epoch 4/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3222 - acc: 0.9882 - val_loss: 0.7085 - val_acc: 0.9306\n",
      "Epoch 5/75\n",
      "198/198 [==============================] - 6s 30ms/step - loss: 0.3093 - acc: 0.9888 - val_loss: 0.7878 - val_acc: 0.9287\n",
      "Epoch 6/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3016 - acc: 0.9883 - val_loss: 0.8399 - val_acc: 0.9293\n",
      "Epoch 7/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3023 - acc: 0.9883 - val_loss: 0.7656 - val_acc: 0.9306\n",
      "Epoch 8/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3288 - acc: 0.9856 - val_loss: 0.6728 - val_acc: 0.9312\n",
      "Epoch 9/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2472 - acc: 0.9763 - val_loss: 0.9931 - val_acc: 0.9217\n",
      "Epoch 10/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2553 - acc: 0.9774 - val_loss: 0.6416 - val_acc: 0.9217\n",
      "Epoch 11/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2862 - acc: 0.9689 - val_loss: 0.9886 - val_acc: 0.8788\n",
      "Epoch 12/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3023 - acc: 0.9822 - val_loss: 0.5944 - val_acc: 0.9223\n",
      "Epoch 13/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1892 - acc: 0.9920 - val_loss: 0.5007 - val_acc: 0.9306\n",
      "Epoch 14/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1615 - acc: 0.9946 - val_loss: 0.5300 - val_acc: 0.9343\n",
      "Epoch 15/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1488 - acc: 0.9962 - val_loss: 0.5394 - val_acc: 0.9381\n",
      "Epoch 16/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1450 - acc: 0.9976 - val_loss: 0.5672 - val_acc: 0.9394\n",
      "Epoch 17/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1433 - acc: 0.9978 - val_loss: 0.5916 - val_acc: 0.9419\n",
      "Epoch 18/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1413 - acc: 0.9976 - val_loss: 0.5865 - val_acc: 0.9400\n",
      "Epoch 19/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1401 - acc: 0.9970 - val_loss: 0.6862 - val_acc: 0.9400\n",
      "Epoch 20/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1375 - acc: 0.9986 - val_loss: 0.7204 - val_acc: 0.9400\n",
      "Epoch 21/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1364 - acc: 0.9976 - val_loss: 0.6854 - val_acc: 0.9407\n",
      "Epoch 22/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1364 - acc: 0.9983 - val_loss: 0.6987 - val_acc: 0.9394\n",
      "Epoch 23/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1334 - acc: 0.9981 - val_loss: 0.7204 - val_acc: 0.9388\n",
      "Epoch 24/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1332 - acc: 0.9979 - val_loss: 0.7463 - val_acc: 0.9400\n",
      "Epoch 25/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1345 - acc: 0.9981 - val_loss: 0.7780 - val_acc: 0.9394\n",
      "Epoch 26/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1337 - acc: 0.9984 - val_loss: 0.7546 - val_acc: 0.9407\n",
      "Epoch 27/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1510 - acc: 0.9981 - val_loss: 0.7542 - val_acc: 0.9369\n",
      "Epoch 28/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2184 - acc: 0.9908 - val_loss: 1.0383 - val_acc: 0.9293\n",
      "Epoch 29/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1815 - acc: 0.9956 - val_loss: 0.6686 - val_acc: 0.9394\n",
      "Epoch 30/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1447 - acc: 0.9961 - val_loss: 0.5614 - val_acc: 0.9356\n",
      "Epoch 31/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1683 - acc: 0.9965 - val_loss: 0.6751 - val_acc: 0.9375\n",
      "Epoch 32/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1322 - acc: 0.9976 - val_loss: 0.7534 - val_acc: 0.9394\n",
      "Epoch 33/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1337 - acc: 0.9983 - val_loss: 0.8100 - val_acc: 0.9337\n",
      "Epoch 34/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1294 - acc: 0.9979 - val_loss: 0.7726 - val_acc: 0.9362\n",
      "Epoch 35/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1316 - acc: 0.9989 - val_loss: 0.8263 - val_acc: 0.9324\n",
      "Epoch 36/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1307 - acc: 0.9984 - val_loss: 0.8201 - val_acc: 0.9356\n",
      "Epoch 37/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1308 - acc: 0.9987 - val_loss: 0.7947 - val_acc: 0.9438\n",
      "Epoch 38/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1316 - acc: 0.9983 - val_loss: 0.6216 - val_acc: 0.9343\n",
      "Epoch 39/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.2524 - acc: 0.9878 - val_loss: 0.7231 - val_acc: 0.9413\n",
      "Epoch 40/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1775 - acc: 0.9945 - val_loss: 0.8837 - val_acc: 0.9255\n",
      "Epoch 41/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1562 - acc: 0.9959 - val_loss: 0.7850 - val_acc: 0.9438\n",
      "Epoch 42/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1373 - acc: 0.9979 - val_loss: 0.8602 - val_acc: 0.9463\n",
      "Epoch 43/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1310 - acc: 0.9989 - val_loss: 0.7923 - val_acc: 0.9318\n",
      "Epoch 44/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1355 - acc: 0.9975 - val_loss: 0.7997 - val_acc: 0.9476\n",
      "Epoch 45/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1319 - acc: 0.9986 - val_loss: 0.7575 - val_acc: 0.9482\n",
      "Epoch 46/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1319 - acc: 0.9989 - val_loss: 0.7933 - val_acc: 0.9482\n",
      "Epoch 47/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1365 - acc: 0.9986 - val_loss: 0.9691 - val_acc: 0.9362\n",
      "Epoch 48/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1947 - acc: 0.9932 - val_loss: 0.8541 - val_acc: 0.9451\n",
      "Epoch 49/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1369 - acc: 0.9968 - val_loss: 0.7065 - val_acc: 0.9444\n",
      "Epoch 50/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1327 - acc: 0.9973 - val_loss: 0.7328 - val_acc: 0.9463\n",
      "Epoch 51/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1269 - acc: 0.9989 - val_loss: 0.8302 - val_acc: 0.9470\n",
      "Epoch 52/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3379 - acc: 0.9847 - val_loss: 1.6852 - val_acc: 0.8990\n",
      "Epoch 53/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3889 - acc: 0.9842 - val_loss: 1.4143 - val_acc: 0.9072\n",
      "Epoch 54/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.3031 - acc: 0.9894 - val_loss: 0.7101 - val_acc: 0.9242\n",
      "Epoch 55/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1642 - acc: 0.9929 - val_loss: 0.6881 - val_acc: 0.9343\n",
      "Epoch 56/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1337 - acc: 0.9976 - val_loss: 0.7422 - val_acc: 0.9350\n",
      "Epoch 57/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1270 - acc: 0.9991 - val_loss: 0.7229 - val_acc: 0.9375\n",
      "Epoch 58/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1255 - acc: 0.9991 - val_loss: 0.7160 - val_acc: 0.9388\n",
      "Epoch 59/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1262 - acc: 0.9975 - val_loss: 0.7342 - val_acc: 0.9375\n",
      "Epoch 60/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1282 - acc: 0.9986 - val_loss: 0.7644 - val_acc: 0.9268\n",
      "Epoch 61/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1267 - acc: 0.9987 - val_loss: 0.8520 - val_acc: 0.9255\n",
      "Epoch 62/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1275 - acc: 0.9986 - val_loss: 0.8771 - val_acc: 0.9274\n",
      "Epoch 63/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1403 - acc: 0.9986 - val_loss: 0.9424 - val_acc: 0.9287\n",
      "Epoch 64/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1287 - acc: 0.9984 - val_loss: 0.8920 - val_acc: 0.9343\n",
      "Epoch 65/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1382 - acc: 0.9968 - val_loss: 0.7392 - val_acc: 0.9381\n",
      "Epoch 66/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1253 - acc: 0.9992 - val_loss: 0.6739 - val_acc: 0.9375\n",
      "Epoch 67/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1278 - acc: 0.9983 - val_loss: 0.6837 - val_acc: 0.9375\n",
      "Epoch 68/75\n",
      "198/198 [==============================] - 6s 30ms/step - loss: 0.1278 - acc: 0.9984 - val_loss: 0.6773 - val_acc: 0.9400\n",
      "Epoch 69/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1252 - acc: 0.9989 - val_loss: 0.7612 - val_acc: 0.9400\n",
      "Epoch 70/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1361 - acc: 0.9975 - val_loss: 0.9608 - val_acc: 0.9230\n",
      "Epoch 71/75\n",
      "198/198 [==============================] - 6s 29ms/step - loss: 0.1430 - acc: 0.9964 - val_loss: 0.7260 - val_acc: 0.9293\n",
      "Epoch 72/75\n",
      "198/198 [==============================] - 6s 30ms/step - loss: 0.1272 - acc: 0.9979 - val_loss: 0.5853 - val_acc: 0.9356\n",
      "Epoch 73/75\n",
      "198/198 [==============================] - 6s 30ms/step - loss: 0.2334 - acc: 0.9929 - val_loss: 0.7014 - val_acc: 0.9407\n",
      "Epoch 74/75\n",
      "198/198 [==============================] - 6s 31ms/step - loss: 0.1573 - acc: 0.9973 - val_loss: 0.6582 - val_acc: 0.9407\n",
      "Epoch 75/75\n",
      "198/198 [==============================] - 6s 30ms/step - loss: 0.1230 - acc: 0.9987 - val_loss: 0.7214 - val_acc: 0.9426\n"
     ]
    }
   ],
   "source": [
    "history_statemodel = state_model.fit(train_x, train_y, batch_size = 32, validation_data = (val_x, val_y), epochs = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_2/embeddings:0' shape=(17317, 100) dtype=float32, numpy=\n",
       " array([[-0.08968937,  0.08269832,  0.06013974, ..., -0.0033683 ,\n",
       "          0.03669983, -0.08458614],\n",
       "        [-0.01123074,  0.01817808, -0.01911442, ...,  0.0026936 ,\n",
       "         -0.00221379, -0.0047959 ],\n",
       "        [ 0.02828863,  0.03257012, -0.0433582 , ...,  0.01739149,\n",
       "         -0.00377206, -0.02932386],\n",
       "        ...,\n",
       "        [ 0.02923309,  0.00359678, -0.04217791, ...,  0.03803669,\n",
       "         -0.01304831, -0.01093927],\n",
       "        [ 0.01023096,  0.00147674,  0.01376358, ..., -0.01292893,\n",
       "         -0.00534817,  0.01604604],\n",
       "        [ 0.0139632 , -0.00550926, -0.00546545, ...,  0.00499245,\n",
       "         -0.0019279 ,  0.01020234]], dtype=float32)>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_statemodel.model.layers[1].weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
